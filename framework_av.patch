#       modified:   camera/CameraParameters.cpp
#       modified:   include/camera/CameraParameters.h
#       modified:   include/media/AudioParameter.h
#       modified:   include/media/AudioRecord.h
#       modified:   include/media/AudioSystem.h
#       modified:   include/media/AudioTrack.h
#       modified:   include/media/IAudioFlinger.h
#       modified:   include/media/IAudioPolicyService.h
#       modified:   include/media/stagefright/ColorConverter.h
#       modified:   include/media/stagefright/MediaDefs.h
#       modified:   include/media/stagefright/OMXCodec.h
#       modified:   include/private/media/AudioTrackShared.h
#       modified:   media/libmedia/AudioParameter.cpp
#       modified:   media/libmedia/AudioRecord.cpp
#       modified:   media/libmedia/AudioSystem.cpp
#       modified:   media/libmedia/AudioTrack.cpp
#       modified:   media/libmedia/IAudioFlinger.cpp
#       modified:   media/libmedia/IAudioPolicyService.cpp
#       modified:   media/libstagefright/ACodec.cpp
#       modified:   media/libstagefright/CameraSource.cpp
#       modified:   media/libstagefright/MediaDefs.cpp
#       modified:   media/libstagefright/OMXCodec.cpp
#       modified:   media/libstagefright/SurfaceMediaSource.cpp
#       modified:   media/libstagefright/colorconversion/ColorConverter.cpp
#       modified:   media/libstagefright/omx/SoftOMXPlugin.cpp
#       modified:   services/audioflinger/Android.mk
#       modified:   services/audioflinger/AudioFlinger.cpp
#       modified:   services/audioflinger/AudioFlinger.h
#       modified:   services/audioflinger/AudioPolicyService.cpp
#       modified:   services/audioflinger/AudioPolicyService.h
#       modified:   services/audioflinger/Effects.h
#       modified:   services/audioflinger/Threads.cpp
#       modified:   services/audioflinger/Threads.h
#       modified:   services/camera/libcameraservice/CameraHardwareInterface.h
diff --git a/frameworks/av/camera/CameraParameters.cpp b/frameworks/av/camera/CameraParameters.cpp
index d661a85..6cff407 100644
--- a/frameworks/av/camera/CameraParameters.cpp
+++ b/frameworks/av/camera/CameraParameters.cpp
@@ -329,6 +329,12 @@ const char CameraParameters::SCENE_MODE_FIREWORKS[] = "fireworks";
 const char CameraParameters::SCENE_MODE_SPORTS[] = "sports";
 const char CameraParameters::SCENE_MODE_PARTY[] = "party";
 const char CameraParameters::SCENE_MODE_CANDLELIGHT[] = "candlelight";
+#ifdef STE_HARDWARE
+const char CameraParameters::SCENE_MODE_BACKLIGHT[] = "backlight";
+const char CameraParameters::SCENE_MODE_DUSKDAWN[] = "duskdawn";
+const char CameraParameters::SCENE_MODE_FALLCOLOR[] = "fallcolor";
+const char CameraParameters::SCENE_MODE_TEXT[] = "text";
+#endif
 #ifdef QCOM_HARDWARE
 #ifdef SAMSUNG_CAMERA_LEGACY
 const char CameraParameters::SCENE_MODE_BACKLIGHT[] = "back-light";
@@ -355,8 +361,18 @@ const char CameraParameters::PIXEL_FORMAT_YUV420SP[] = "yuv420sp";
 #ifdef QCOM_HARDWARE
 const char CameraParameters::PIXEL_FORMAT_YUV420SP_ADRENO[] = "yuv420sp-adreno";
 #endif
+#ifdef STE_HARDWARE
+const char CameraParameters::PIXEL_FORMAT_YUV420SPNV12[] = "yuv420spnv12";
+#endif
 const char CameraParameters::PIXEL_FORMAT_YUV422I[] = "yuv422i-yuyv";
 const char CameraParameters::PIXEL_FORMAT_YUV420P[]  = "yuv420p";
+#ifdef STE_HARDWARE
+const char CameraParameters::PIXEL_FORMAT_YUV420MB[] = "yuv420mb";
+const char CameraParameters::PIXEL_FORMAT_YVU422SP[] = "yvu422sp";
+const char CameraParameters::PIXEL_FORMAT_YVU422P[] = "yvu422p";
+const char CameraParameters::PIXEL_FORMAT_YVU420SP[] = "yvu420sp";
+const char CameraParameters::PIXEL_FORMAT_YVU420P[]  = "yvu420p";
+#endif
 const char CameraParameters::PIXEL_FORMAT_RGB565[] = "rgb565";
 const char CameraParameters::PIXEL_FORMAT_RGBA8888[] = "rgba8888";
 const char CameraParameters::PIXEL_FORMAT_JPEG[] = "jpeg";
@@ -512,6 +528,23 @@ const char CameraParameters::SCENE_MODE_FALL_COLOR[] = "fall-color";
 const char CameraParameters::SCENE_MODE_TEXT[] = "text";
 #endif
 
+#ifdef STE_HARDWARE
+const char CameraParameters::FOCUS_MODE_FACEDETECT[] = "facedetect";
+const char CameraParameters::FOCUS_MODE_TOUCHAF[] = "touchaf";
+const char CameraParameters::ISO_50[] = "ISO50";
+const char CameraParameters::KEY_ANTI_SHAKE_MODE[] = "antishake";
+const char CameraParameters::KEY_AUTO_CONTRAST[] = "auto-contrast";
+const char CameraParameters::KEY_BEAUTY_MODE[] = "beauty";
+const char CameraParameters::KEY_BLUR_MODE[] = "blur";
+const char CameraParameters::KEY_VINTAGE_MODE[] = "vintagemode";
+const char CameraParameters::KEY_WDR_MODE[] = "wdr";
+const char CameraParameters::VINTAGE_MODE_BNW[] = "bnw";
+const char CameraParameters::VINTAGE_MODE_COOL[] = "cool";
+const char CameraParameters::VINTAGE_MODE_NORMAL[] = "normal";
+const char CameraParameters::VINTAGE_MODE_OFF[] = "off";
+const char CameraParameters::VINTAGE_MODE_WARM[] = "warm";
+#endif 
+
 static const char* portrait = "portrait";
 static const char* landscape = "landscape";
 
@@ -532,6 +565,11 @@ void CameraParameters::setOrientation(int orientation)
 }
 #endif
 
+#ifdef STE_HARDWARE
+// keys for record stride and sliceheight
+const char CameraParameters::KEY_RECORD_STRIDE[] = "record-stride";
+const char CameraParameters::KEY_RECORD_SLICE_HEIGHT[] = "record-slice-height";
+#endif
 
 // Values for light fx settings
 const char CameraParameters::LIGHTFX_LOWLIGHT[] = "low-light";
diff --git a/frameworks/av/include/camera/CameraParameters.h b/frameworks/av/include/camera/CameraParameters.h
index 2758989..a0e3239 100644
--- a/frameworks/av/include/camera/CameraParameters.h
+++ b/frameworks/av/include/camera/CameraParameters.h
@@ -834,6 +834,12 @@ public:
     static const char SCENE_MODE_FLOWERS[];
     static const char SCENE_MODE_AR[];
 #endif
+#ifdef STE_HARDWARE
+    static const char SCENE_MODE_BACKLIGHT[];
+    static const char SCENE_MODE_DUSKDAWN[];
+    static const char SCENE_MODE_FALLCOLOR[];
+    static const char SCENE_MODE_TEXT[];
+#endif
     // Applications are looking for a barcode. Camera driver will be optimized
     // for barcode reading.
     static const char SCENE_MODE_BARCODE[];
@@ -853,8 +859,18 @@ public:
 #ifdef QCOM_HARDWARE
     static const char PIXEL_FORMAT_YUV420SP_ADRENO[]; // ADRENO
 #endif
+#ifdef STE_HARDWARE
+    static const char PIXEL_FORMAT_YUV420SPNV12[]; // NV12
+#endif
     static const char PIXEL_FORMAT_YUV422I[]; // YUY2
     static const char PIXEL_FORMAT_YUV420P[]; // YV12
+#ifdef STE_HARDWARE
+    static const char PIXEL_FORMAT_YVU422SP[];
+    static const char PIXEL_FORMAT_YVU422P[];
+    static const char PIXEL_FORMAT_YVU420SP[];
+    static const char PIXEL_FORMAT_YVU420P[];
+    static const char PIXEL_FORMAT_YUV420MB[];
+#endif
     static const char PIXEL_FORMAT_RGB565[];
     static const char PIXEL_FORMAT_RGBA8888[];
     static const char PIXEL_FORMAT_JPEG[];
@@ -1062,6 +1078,27 @@ public:
     static const char SCENE_MODE_TEXT[];
 #endif
 
+#ifdef STE_HARDWARE
+    static const char FOCUS_MODE_FACEDETECT[];
+    static const char FOCUS_MODE_TOUCHAF[];
+    static const char ISO_50[];
+    static const char KEY_ANTI_SHAKE_MODE[];
+    static const char KEY_AUTO_CONTRAST[];
+    static const char KEY_BEAUTY_MODE[];
+    static const char KEY_BLUR_MODE[];
+    static const char KEY_VINTAGE_MODE[];
+    static const char KEY_WDR_MODE[];
+    static const char VINTAGE_MODE_BNW[];
+    static const char VINTAGE_MODE_COOL[];
+    static const char VINTAGE_MODE_NORMAL[];
+    static const char VINTAGE_MODE_OFF[];
+    static const char VINTAGE_MODE_WARM[];
+    static const char SCENE_MODE_DUSKDAWN[];
+    static const char SCENE_MODE_FALL[];
+    static const char SCENE_MODE_FALL_COLOR[];
+    static const char SCENE_MODE_TEXT[];
+#endif
+
    // Values for Redeye Reduction settings.
    // static const char REDEYE_REDUCTION_ENABLE[];
    // static const char REDEYE_REDUCTION_DISABLE[];
@@ -1083,6 +1120,12 @@ public:
     void getSupportedHfrSizes(Vector<Size> &sizes) const;
 #endif
 
+#ifdef STE_HARDWARE
+    // keys for record stride and slice height
+    static const char KEY_RECORD_STRIDE[];
+    static const char KEY_RECORD_SLICE_HEIGHT[];
+#endif
+
 private:
     DefaultKeyedVector<String8,String8>    mMap;
 };
diff --git a/frameworks/av/include/media/AudioParameter.h b/frameworks/av/include/media/AudioParameter.h
index 72591f6..0976062 100644
--- a/frameworks/av/include/media/AudioParameter.h
+++ b/frameworks/av/include/media/AudioParameter.h
@@ -59,6 +59,9 @@ public:
     static const char * const keyADSPStatus;
     static const char * const keyCanOpenProxy;
     static const char * const keyFmVolume;
+#ifdef STE_AUDIO
+    static const char *keySinkLatency;
+#endif
 
     String8 toString();
 
diff --git a/frameworks/av/include/media/AudioRecord.h b/frameworks/av/include/media/AudioRecord.h
index 6a2aec1..fca1863 100644
--- a/frameworks/av/include/media/AudioRecord.h
+++ b/frameworks/av/include/media/AudioRecord.h
@@ -167,7 +167,6 @@ public:
                             bool threadCanCallJava = false,
                             int sessionId = 0);
 
-
     /* Result of constructing the AudioRecord. This must be checked
      * before using any AudioRecord API (except for set()), because using
      * an uninitialized AudioRecord produces undefined results.
@@ -400,6 +399,9 @@ private:
     int                     mPreviousPriority;          // before start()
     SchedPolicy             mPreviousSchedulingGroup;
     AudioRecordClientProxy* mProxy;
+#ifdef STE_AUDIO
+    audio_input_clients     *mpInputClientId;
+#endif
 };
 
 }; // namespace android
diff --git a/frameworks/av/include/media/AudioSystem.h b/frameworks/av/include/media/AudioSystem.h
index 6c04a48..53a25e9 100644
--- a/frameworks/av/include/media/AudioSystem.h
+++ b/frameworks/av/include/media/AudioSystem.h
@@ -32,6 +32,9 @@
 namespace android {
 
 typedef void (*audio_error_callback)(status_t err);
+#ifdef STE_AUDIO
+typedef void (*latency_update_callback)(void *cookie, audio_io_handle_t output, uint32_t sinkLatency);
+#endif
 
 class IAudioPolicyService;
 class String8;
@@ -143,6 +146,11 @@ public:
     static void acquireAudioSessionId(int audioSession);
     static void releaseAudioSessionId(int audioSession);
 
+#ifdef STE_AUDIO
+    static int registerLatencyNotificationClient(latency_update_callback cb, void *cookie, audio_io_handle_t output);
+    static void unregisterLatencyNotificationClient(int clientId);
+#endif
+
     // types of io configuration change events received with ioConfigChanged()
     enum io_config_event {
         OUTPUT_OPENED,
@@ -156,6 +164,9 @@ public:
         A2DP_OUTPUT_STATE,
         EFFECT_CONFIG_CHANGED,
 #endif
+#ifdef STE_AUDIO
+        SINK_LATENCY_CHANGED,
+#endif
         NUM_CONFIG_EVENTS
     };
 
@@ -218,7 +229,13 @@ public:
                                     uint32_t samplingRate = 0,
                                     audio_format_t format = AUDIO_FORMAT_DEFAULT,
                                     audio_channel_mask_t channelMask = AUDIO_CHANNEL_IN_MONO,
+#ifdef STE_AUDIO
+                                    audio_in_acoustics_t acoustics = (audio_in_acoustics_t)0,
+                                    int sessionId = 0,
+                                    audio_input_clients *inputClientId = NULL);
+#else
                                     int sessionId = 0);
+#endif
     static status_t startInput(audio_io_handle_t input);
     static status_t stopInput(audio_io_handle_t input);
     static void releaseInput(audio_io_handle_t input);
@@ -284,6 +301,14 @@ private:
         virtual void binderDied(const wp<IBinder>& who);
     };
 
+#ifdef STE_AUDIO
+    struct NotificationClient : public RefBase {
+        latency_update_callback mCb;
+        void *mCookie;
+        audio_io_handle_t mOutput;
+    };
+#endif
+
     static sp<AudioFlingerClient> gAudioFlingerClient;
     static sp<AudioPolicyServiceClient> gAudioPolicyServiceClient;
     friend class AudioFlingerClient;
@@ -306,6 +331,12 @@ private:
     // list of output descriptors containing cached parameters
     // (sampling rate, framecount, channel count...)
     static DefaultKeyedVector<audio_io_handle_t, OutputDescriptor *> gOutputs;
+
+#ifdef STE_AUDIO
+    static Mutex gLatencyLock;
+    static int gNextUniqueLatencyId;
+    static DefaultKeyedVector<int, sp<AudioSystem::NotificationClient> > gLatencyNotificationClients;
+#endif
 };
 
 };  // namespace android
diff --git a/frameworks/av/include/media/AudioTrack.h b/frameworks/av/include/media/AudioTrack.h
index 9f8446b..ffef742 100644
--- a/frameworks/av/include/media/AudioTrack.h
+++ b/frameworks/av/include/media/AudioTrack.h
@@ -75,7 +75,11 @@ public:
         EVENT_NEW_POS = 4,          // Playback head is at a new position
                                     // (See setPositionUpdatePeriod()).
         EVENT_BUFFER_END = 5,       // Playback head is at the end of the buffer.
+#ifdef STE_AUDIO
+        EVENT_LATENCY_CHANGED = 6   // Audio sink latency has changed.
+#else
         EVENT_HW_FAIL = 6,          // ADSP failure.
+#endif
     };
 
     /* Client should declare Buffer on the stack and pass address to obtainBuffer()
@@ -548,6 +552,10 @@ protected:
             audio_io_handle_t getOutput_l();
             status_t restoreTrack_l(audio_track_cblk_t*& cblk, bool fromStart);
             bool stopped_l() const { return !mActive; }
+#ifdef STE_AUDIO
+            static void LatencyCallback(void *cookie, audio_io_handle_t output,
+                                 uint32_t sinkLatency);
+#endif
 
 #ifdef QCOM_HARDWARE
     sp<IDirectTrack>        mDirectTrack;
@@ -625,6 +633,9 @@ protected:
     SchedPolicy             mPreviousSchedulingGroup;
     AudioTrackClientProxy*  mProxy;
     bool                    mAwaitBoost;    // thread should wait for priority boost before running
+#ifdef STE_AUDIO
+    int                     mLatencyClientId;
+#endif
 };
 
 class TimedAudioTrack : public AudioTrack
diff --git a/frameworks/av/include/media/IAudioFlinger.h b/frameworks/av/include/media/IAudioFlinger.h
index 2ad1eeb..380e4b9 100644
--- a/frameworks/av/include/media/IAudioFlinger.h
+++ b/frameworks/av/include/media/IAudioFlinger.h
@@ -165,12 +165,26 @@ public:
     virtual status_t suspendOutput(audio_io_handle_t output) = 0;
     virtual status_t restoreOutput(audio_io_handle_t output) = 0;
 
+#ifdef STE_AUDIO
+    virtual uint32_t *addInputClient(uint32_t clientId) = 0;
+    virtual status_t removeInputClient(uint32_t *pClientId) = 0;
+
+    virtual audio_io_handle_t openInput(audio_module_handle_t module,
+                                        audio_devices_t *pDevices,
+                                        uint32_t *pSamplingRate,
+                                        audio_format_t *pFormat,
+                                        audio_channel_mask_t *pChannelMask,
+                                        audio_input_clients *inputClientId = NULL) = 0;
+    virtual status_t closeInput(audio_io_handle_t input,
+                                audio_input_clients *inputClientId = NULL) = 0;
+#else
     virtual audio_io_handle_t openInput(audio_module_handle_t module,
                                         audio_devices_t *pDevices,
                                         uint32_t *pSamplingRate,
                                         audio_format_t *pFormat,
                                         audio_channel_mask_t *pChannelMask) = 0;
     virtual status_t closeInput(audio_io_handle_t input) = 0;
+#endif
 
     virtual status_t setStreamOutput(audio_stream_type_t stream, audio_io_handle_t output) = 0;
 
@@ -206,6 +220,14 @@ public:
     virtual status_t moveEffects(int session, audio_io_handle_t srcOutput,
                                     audio_io_handle_t dstOutput) = 0;
 
+#ifdef STE_AUDIO
+    virtual size_t readInput(audio_io_handle_t input,
+                            audio_input_clients inputClientId,
+                            void *buffer,
+                            uint32_t bytes,
+                            uint32_t *pOverwrittenBytes) = 0;
+#endif
+
     virtual audio_module_handle_t loadHwModule(const char *name) = 0;
 #ifdef QCOM_HARDWARE
     virtual status_t deregisterClient(const sp<IAudioFlingerClient>& client) { return false; };
diff --git a/frameworks/av/include/media/IAudioPolicyService.h b/frameworks/av/include/media/IAudioPolicyService.h
index b5ad4ef..efa6fd1 100644
--- a/frameworks/av/include/media/IAudioPolicyService.h
+++ b/frameworks/av/include/media/IAudioPolicyService.h
@@ -65,7 +65,12 @@ public:
                                     uint32_t samplingRate = 0,
                                     audio_format_t format = AUDIO_FORMAT_DEFAULT,
                                     audio_channel_mask_t channelMask = 0,
+#ifdef STE_AUDIO
+                                    int audioSession = 0,
+                                    audio_input_clients *inputClientId = NULL) = 0;
+#else
                                     int audioSession = 0) = 0;
+#endif
     virtual status_t startInput(audio_io_handle_t input) = 0;
     virtual status_t stopInput(audio_io_handle_t input) = 0;
     virtual void releaseInput(audio_io_handle_t input) = 0;
diff --git a/frameworks/av/include/media/stagefright/ColorConverter.h b/frameworks/av/include/media/stagefright/ColorConverter.h
index 85ba920..014fc7a 100644
--- a/frameworks/av/include/media/stagefright/ColorConverter.h
+++ b/frameworks/av/include/media/stagefright/ColorConverter.h
@@ -73,6 +73,11 @@ private:
     status_t convertQCOMYUV420SemiPlanar(
             const BitmapParams &src, const BitmapParams &dst);
 
+#ifdef STE_HARDWARE
+    status_t convertSTEYUV420PackedSemiPlanarMB(
+            const BitmapParams &src, const BitmapParams &dst);
+#endif
+
     status_t convertYUV420SemiPlanar(
             const BitmapParams &src, const BitmapParams &dst);
 
diff --git a/frameworks/av/include/media/stagefright/MediaDefs.h b/frameworks/av/include/media/stagefright/MediaDefs.h
index c750717..74db544 100644
--- a/frameworks/av/include/media/stagefright/MediaDefs.h
+++ b/frameworks/av/include/media/stagefright/MediaDefs.h
@@ -29,8 +29,14 @@ extern const char *MEDIA_MIMETYPE_VIDEO_VPX;
 extern const char *MEDIA_MIMETYPE_VIDEO_AVC;
 extern const char *MEDIA_MIMETYPE_VIDEO_MPEG4;
 extern const char *MEDIA_MIMETYPE_VIDEO_H263;
+#ifdef STE_HARDWARE
+extern const char *MEDIA_MIMETYPE_VIDEO_H263_SW;
+#endif
 extern const char *MEDIA_MIMETYPE_VIDEO_MPEG2;
 extern const char *MEDIA_MIMETYPE_VIDEO_RAW;
+#ifdef STE_HARDWARE
+extern const char *MEDIA_MIMETYPE_VIDEO_VC1;
+#endif
 
 extern const char *MEDIA_MIMETYPE_AUDIO_AMR_NB;
 extern const char *MEDIA_MIMETYPE_AUDIO_AMR_WB;
diff --git a/frameworks/av/include/media/stagefright/OMXCodec.h b/frameworks/av/include/media/stagefright/OMXCodec.h
index 22d790e..dffd72b 100644
--- a/frameworks/av/include/media/stagefright/OMXCodec.h
+++ b/frameworks/av/include/media/stagefright/OMXCodec.h
@@ -89,6 +89,10 @@ struct OMXCodec : public MediaSource,
     // from MediaBufferObserver
     virtual void signalBufferReturned(MediaBuffer *buffer);
 
+#ifdef STE_HARDWARE
+    static uint32_t OmxToHALFormat(OMX_COLOR_FORMATTYPE omxValue);
+#endif
+
     enum Quirks {
         kNeedsFlushBeforeDisable              = 1,
         kWantsNALFragments                    = 2,
@@ -110,6 +114,9 @@ struct OMXCodec : public MediaSource,
         kRequiresGlobalFlush                  = 0x20000000, // 2^29
         kRequiresWMAProComponent              = 0x40000000, //2^30
 #endif
+#ifdef STE_HARDWARE
+        kRequiresStoreMetaDataBeforeIdle      = 16384,
+#endif
     };
 
     struct CodecNameAndQuirks {
diff --git a/frameworks/av/include/private/media/AudioTrackShared.h b/frameworks/av/include/private/media/AudioTrackShared.h
index 41e20f8..1e96458 100644
--- a/frameworks/av/include/private/media/AudioTrackShared.h
+++ b/frameworks/av/include/private/media/AudioTrackShared.h
@@ -71,6 +71,11 @@ struct audio_track_cblk_t
                 uint32_t    userBase;
                 uint32_t    serverBase;
 
+                // if there is a shared buffer, "buffers" is the value of pointer() for the shared
+                // buffer, otherwise "buffers" points immediately after the control block
+                void*       buffers;
+                uint32_t    frameCount;
+
                 int         mPad1;          // unused, but preserves cache line alignment
 
                 size_t      frameCount_;    // used during creation to pass actual track buffer size
@@ -97,6 +102,8 @@ private:
                 uint8_t     mPad2;           // unused
 
 public:
+                uint32_t    sampleRate;
+
                 // read-only for client, server writes once at initialization and is then read-only
                 uint8_t     mName;           // normal tracks: track name, fast tracks: track index
 
diff --git a/frameworks/av/media/libmedia/AudioParameter.cpp b/frameworks/av/media/libmedia/AudioParameter.cpp
index 18fcca4..e6be77c 100644
--- a/frameworks/av/media/libmedia/AudioParameter.cpp
+++ b/frameworks/av/media/libmedia/AudioParameter.cpp
@@ -43,6 +43,9 @@ const char * const AudioParameter::keyHandleA2dpDevice = AUDIO_PARAMETER_KEY_HAN
 const char * const AudioParameter::keyADSPStatus = AUDIO_PARAMETER_KEY_ADSP_STATUS;
 const char * const AudioParameter::keyCanOpenProxy = AUDIO_CAN_OPEN_PROXY;
 const char * const AudioParameter::keyFmVolume = AUDIO_PARAMETER_KEY_FM_VOLUME;
+#ifdef STE_AUDIO
+const char *AudioParameter::keySinkLatency = "sink_latency";
+#endif
 
 AudioParameter::AudioParameter(const String8& keyValuePairs)
 {
diff --git a/frameworks/av/media/libmedia/AudioRecord.cpp b/frameworks/av/media/libmedia/AudioRecord.cpp
index 9a0328a..7917339 100644
--- a/frameworks/av/media/libmedia/AudioRecord.cpp
+++ b/frameworks/av/media/libmedia/AudioRecord.cpp
@@ -82,9 +82,19 @@ status_t AudioRecord::getMinFrameCount(
 
 AudioRecord::AudioRecord()
     : mStatus(NO_INIT), mSessionId(0),
+#ifdef STE_AUDIO
+      mpInputClientId(NULL),
+#endif
       mPreviousPriority(ANDROID_PRIORITY_NORMAL), mPreviousSchedulingGroup(SP_DEFAULT),
       mProxy(NULL)
 {
+#ifdef STE_AUDIO
+    const sp<IAudioFlinger>& audioFlinger = AudioSystem::get_audio_flinger();
+    if (audioFlinger != 0) {
+        mpInputClientId = (audio_input_clients*)audioFlinger->addInputClient(
+                                                 (uint32_t)AUDIO_INPUT_CLIENT_RECORD);
+    }
+#endif
 }
 
 AudioRecord::AudioRecord(
@@ -98,10 +108,21 @@ AudioRecord::AudioRecord(
         int notificationFrames,
         int sessionId)
     : mStatus(NO_INIT), mSessionId(0),
+#ifdef STE_AUDIO
+      mpInputClientId(NULL),
+#endif
       mPreviousPriority(ANDROID_PRIORITY_NORMAL),
       mPreviousSchedulingGroup(SP_DEFAULT),
       mProxy(NULL)
 {
+#ifdef STE_AUDIO
+    const sp<IAudioFlinger>& audioFlinger = AudioSystem::get_audio_flinger();
+    if (audioFlinger != 0) {
+        mpInputClientId = (audio_input_clients*)audioFlinger->addInputClient(
+                                                 (uint32_t)AUDIO_INPUT_CLIENT_RECORD);
+    }
+#endif
+
     mStatus = set(inputSource, sampleRate, format, channelMask,
             frameCount, cbf, user, notificationFrames, false /*threadCanCallJava*/, sessionId);
 }
@@ -122,6 +143,12 @@ AudioRecord::~AudioRecord()
         IPCThreadState::self()->flushCommands();
         AudioSystem::releaseAudioSessionId(mSessionId);
     }
+#ifdef STE_AUDIO
+    const sp<IAudioFlinger>& audioFlinger = AudioSystem::get_audio_flinger();
+    if (audioFlinger != 0) {
+        audioFlinger->removeInputClient((uint32_t*)mpInputClientId);
+    }
+#endif
     delete mProxy;
 }
 
@@ -213,7 +240,13 @@ status_t AudioRecord::set(
                                                     sampleRate,
                                                     format,
                                                     channelMask,
+#ifdef STE_AUDIO
+                                                    (audio_in_acoustics_t)0,
+                                                    mSessionId,
+                                                    mpInputClientId);
+#else
                                                     mSessionId);
+#endif
     if (input == 0) {
         ALOGE("Could not get audio input for record source %d", inputSource);
         return BAD_VALUE;
@@ -376,6 +409,12 @@ size_t AudioRecord::frameSize() const
             return sizeof(uint8_t);
         }
     }
+#ifdef STE_AUDIO
+    const sp<IAudioFlinger>& audioFlinger = AudioSystem::get_audio_flinger();
+    if (audioFlinger != 0) {
+        audioFlinger->removeInputClient((uint32_t*)mpInputClientId);
+    }
+#endif
 }
 #endif
 
@@ -720,6 +759,7 @@ audio_io_handle_t AudioRecord::getInput_l()
                                 mSampleRate,
                                 mFormat,
                                 mChannelMask,
+                                (audio_in_acoustics_t)0,
                                 mSessionId);
     return mInput;
 }
diff --git a/frameworks/av/media/libmedia/AudioSystem.cpp b/frameworks/av/media/libmedia/AudioSystem.cpp
index 5c8c1fe..819a34e 100644
--- a/frameworks/av/media/libmedia/AudioSystem.cpp
+++ b/frameworks/av/media/libmedia/AudioSystem.cpp
@@ -44,6 +44,12 @@ audio_format_t AudioSystem::gPrevInFormat = AUDIO_FORMAT_PCM_16_BIT;
 audio_channel_mask_t AudioSystem::gPrevInChannelMask = AUDIO_CHANNEL_IN_MONO;
 size_t AudioSystem::gInBuffSize = 0;
 
+#ifdef STE_AUDIO
+// Clients for receiving latency update notifications
+Mutex AudioSystem::gLatencyLock;
+int AudioSystem::gNextUniqueLatencyId = 0;
+DefaultKeyedVector<int, sp<AudioSystem::NotificationClient> > AudioSystem::gLatencyNotificationClients(0);
+#endif
 
 // establish binder interface to AudioFlinger service
 const sp<IAudioFlinger>& AudioSystem::get_audio_flinger()
@@ -413,9 +419,36 @@ status_t AudioSystem::setFmVolume(float value)
 }
 #endif
 
+#ifdef STE_AUDIO
+int AudioSystem::registerLatencyNotificationClient(latency_update_callback cb,
+        void *cookie, audio_io_handle_t output) {
+    Mutex::Autolock _l(gLatencyLock);
+
+    sp<NotificationClient> notificationClient = new NotificationClient();
+    notificationClient->mCb = cb;
+    notificationClient->mCookie = cookie;
+    notificationClient->mOutput = output;
+
+    gNextUniqueLatencyId++;
+    gLatencyNotificationClients.add(gNextUniqueLatencyId, notificationClient);
+    return gNextUniqueLatencyId;
+}
+
+void AudioSystem::unregisterLatencyNotificationClient(int clientId) {
+    Mutex::Autolock _l(gLatencyLock);
+    gLatencyNotificationClients.removeItem(clientId);
+}
+#endif
+
 // ---------------------------------------------------------------------------
 
 void AudioSystem::AudioFlingerClient::binderDied(const wp<IBinder>& who) {
+#ifdef STE_AUDIO
+    gLatencyLock.lock();
+    AudioSystem::gLatencyNotificationClients.clear();
+    gLatencyLock.unlock();
+#endif
+
     Mutex::Autolock _l(AudioSystem::gLock);
 
     AudioSystem::gAudioFlinger.clear();
@@ -484,6 +517,22 @@ void AudioSystem::AudioFlingerClient::ioConfigChanged(int event, audio_io_handle
         outputDesc =  new OutputDescriptor(*desc);
         gOutputs.replaceValueFor(ioHandle, outputDesc);
     } break;
+#ifdef STE_AUDIO
+    case SINK_LATENCY_CHANGED: {
+        int sinkLatency = *((int*)param2);
+        gLock.unlock();
+        gLatencyLock.lock();
+        size_t size = gLatencyNotificationClients.size();
+        for (size_t i = 0; i < size; i++) {
+            sp<NotificationClient> client = gLatencyNotificationClients.valueAt(i);
+            if (client->mOutput == ioHandle) {
+                (*client->mCb)(client->mCookie, ioHandle, sinkLatency);
+            }
+        }
+        gLatencyLock.unlock();
+        gLock.lock();
+    } break;
+#endif
     case INPUT_OPENED:
     case INPUT_CLOSED:
     case INPUT_CONFIG_CHANGED:
@@ -644,11 +693,21 @@ audio_io_handle_t AudioSystem::getInput(audio_source_t inputSource,
                                     uint32_t samplingRate,
                                     audio_format_t format,
                                     audio_channel_mask_t channelMask,
+#ifdef STE_AUDIO
+                                    audio_in_acoustics_t acoustics,
+                                    int sessionId,
+                                    audio_input_clients *inputClientId)
+#else
                                     int sessionId)
+#endif
 {
     const sp<IAudioPolicyService>& aps = AudioSystem::get_audio_policy_service();
     if (aps == 0) return 0;
+#ifdef STE_AUDIO
+    return aps->getInput(inputSource, samplingRate, format, channelMask, sessionId, inputClientId);
+#else
     return aps->getInput(inputSource, samplingRate, format, channelMask, sessionId);
+#endif
 }
 
 status_t AudioSystem::startInput(audio_io_handle_t input)
diff --git a/frameworks/av/media/libmedia/AudioTrack.cpp b/frameworks/av/media/libmedia/AudioTrack.cpp
index 8d066ac..ea75491 100644
--- a/frameworks/av/media/libmedia/AudioTrack.cpp
+++ b/frameworks/av/media/libmedia/AudioTrack.cpp
@@ -204,6 +204,9 @@ AudioTrack::~AudioTrack()
         AudioSystem::releaseAudioSessionId(mSessionId);
 #endif
     }
+#ifdef STE_AUDIO
+        AudioSystem::unregisterLatencyNotificationClient(mLatencyClientId);
+#endif
     delete mProxy;
 }
 
@@ -420,6 +423,7 @@ status_t AudioTrack::set(
 #ifndef QCOM_HARDWARE
     AudioSystem::acquireAudioSessionId(mSessionId);
 #endif
+
     return NO_ERROR;
 }
 
@@ -1095,6 +1099,11 @@ status_t AudioTrack::createTrack_l(
         // Force buffer full condition as data is already present in shared memory
         mProxy->stepUser(frameCount);
     }
+#ifdef STE_AUDIO
+    if (mLatencyClientId != -1) {
+        AudioSystem::unregisterLatencyNotificationClient(mLatencyClientId);
+    }
+#endif
 
     return NO_ERROR;
 }
@@ -1670,6 +1679,15 @@ status_t AudioTrack::getTimeStamp(uint64_t *tstamp) {
     return NO_ERROR;
 }
 #endif
+
+#ifdef STE_AUDIO
+// static
+void AudioTrack::LatencyCallback(void *cookie, audio_io_handle_t output, uint32_t sinkLatency)
+{
+    AudioTrack *me = static_cast<AudioTrack *>(cookie);
+    me->mLatency = sinkLatency + (1000*me->mCblk->frameCount) / me->mCblk->sampleRate;
+}
+#endif
 // =========================================================================
 
 AudioTrack::AudioTrackThread::AudioTrackThread(AudioTrack& receiver, bool bCanCallJava)
diff --git a/frameworks/av/media/libmedia/IAudioFlinger.cpp b/frameworks/av/media/libmedia/IAudioFlinger.cpp
index f9d6ed7..2af2683 100644
--- a/frameworks/av/media/libmedia/IAudioFlinger.cpp
+++ b/frameworks/av/media/libmedia/IAudioFlinger.cpp
@@ -58,6 +58,10 @@ enum {
     CLOSE_OUTPUT,
     SUSPEND_OUTPUT,
     RESTORE_OUTPUT,
+#ifdef STE_AUDIO
+    ADD_INPUT_CLIENT,
+    REMOVE_INPUT_CLIENT,
+#endif
     OPEN_INPUT,
     CLOSE_INPUT,
     SET_STREAM_OUTPUT,
@@ -81,6 +85,9 @@ enum {
 #ifdef QCOM_HARDWARE
     CREATE_DIRECT_TRACK,
 #endif
+#ifdef STE_AUDIO
+    READ_INPUT
+#endif
 };
 
 class BpAudioFlinger : public BpInterface<IAudioFlinger>
@@ -483,11 +490,36 @@ public:
         return reply.readInt32();
     }
 
+#ifdef STE_AUDIO
+    virtual uint32_t *addInputClient(uint32_t clientId)
+    {
+        Parcel data, reply;
+        data.writeInterfaceToken(IAudioFlinger::getInterfaceDescriptor());
+        data.writeInt32(clientId);
+        remote()->transact(ADD_INPUT_CLIENT, data, &reply);
+        return (uint32_t*) reply.readIntPtr();
+    }
+
+    virtual status_t removeInputClient(uint32_t *pClientId)
+    {
+        Parcel data, reply;
+        data.writeInterfaceToken(IAudioFlinger::getInterfaceDescriptor());
+        data.writeIntPtr((intptr_t)pClientId);
+        remote()->transact(REMOVE_INPUT_CLIENT, data, &reply);
+        return reply.readInt32();
+    }
+#endif
+
     virtual audio_io_handle_t openInput(audio_module_handle_t module,
                                         audio_devices_t *pDevices,
                                         uint32_t *pSamplingRate,
                                         audio_format_t *pFormat,
+#ifdef STE_AUDIO
+                                        audio_channel_mask_t *pChannelMask,
+                                        audio_input_clients *pInputClientId)
+#else
                                         audio_channel_mask_t *pChannelMask)
+#endif
     {
         Parcel data, reply;
         audio_devices_t devices = pDevices ? *pDevices : (audio_devices_t)0;
@@ -501,6 +533,9 @@ public:
         data.writeInt32(samplingRate);
         data.writeInt32(format);
         data.writeInt32(channelMask);
+#ifdef STE_AUDIO
+        data.writeIntPtr((intptr_t)pInputClientId);
+#endif
         remote()->transact(OPEN_INPUT, data, &reply);
         audio_io_handle_t input = (audio_io_handle_t) reply.readInt32();
         devices = (audio_devices_t)reply.readInt32();
@@ -514,7 +549,11 @@ public:
         return input;
     }
 
+#ifdef STE_AUDIO
+    virtual status_t closeInput(int input, audio_input_clients *inputClientId)
+#else
     virtual status_t closeInput(int input)
+#endif
     {
         Parcel data, reply;
         data.writeInterfaceToken(IAudioFlinger::getInterfaceDescriptor());
@@ -572,6 +611,22 @@ public:
         return reply.readInt32();
     }
 
+#ifdef STE_AUDIO
+    virtual size_t readInput(audio_io_handle_t input, audio_input_clients inputClientId,
+            void *buffer, uint32_t bytes, uint32_t *pOverwrittenBytes)
+    {
+        Parcel data, reply;
+        data.writeInterfaceToken(IAudioFlinger::getInterfaceDescriptor());
+        data.writeInt32(input);
+        data.writeInt32((uint32_t) inputClientId);
+        data.writeIntPtr((intptr_t) buffer);
+        data.writeInt32(bytes);
+        data.writeIntPtr((intptr_t) pOverwrittenBytes);
+        remote()->transact(READ_INPUT, data, &reply);
+        return reply.readInt32();
+    }
+#endif
+
     virtual int newAudioSessionId()
     {
         Parcel data, reply;
@@ -988,6 +1043,20 @@ status_t BnAudioFlinger::onTransact(
             reply->writeInt32(restoreOutput((audio_io_handle_t) data.readInt32()));
             return NO_ERROR;
         } break;
+#ifdef STE_AUDIO
+        case ADD_INPUT_CLIENT: {
+            CHECK_INTERFACE(IAudioFlinger, data, reply);
+            uint32_t clientId = data.readInt32();
+            reply->writeIntPtr((intptr_t)addInputClient(clientId));
+            return NO_ERROR;
+        } break;
+        case REMOVE_INPUT_CLIENT: {
+            CHECK_INTERFACE(IAudioFlinger, data, reply);
+            uint32_t *pClientId = (uint32_t*) data.readIntPtr();
+            reply->writeInt32(removeInputClient(pClientId));
+            return NO_ERROR;
+        } break;
+#endif
         case OPEN_INPUT: {
             CHECK_INTERFACE(IAudioFlinger, data, reply);
             audio_module_handle_t module = (audio_module_handle_t)data.readInt32();
@@ -995,12 +1064,20 @@ status_t BnAudioFlinger::onTransact(
             uint32_t samplingRate = data.readInt32();
             audio_format_t format = (audio_format_t) data.readInt32();
             audio_channel_mask_t channelMask = (audio_channel_mask_t)data.readInt32();
+#ifdef STE_AUDIO
+            audio_input_clients *inputClientId = (audio_input_clients*) data.readIntPtr();
+#endif
 
             audio_io_handle_t input = openInput(module,
                                              &devices,
                                              &samplingRate,
                                              &format,
+#ifdef STE_AUDIO
+                                             &channelMask,
+                                             inputClientId);
+#else
                                              &channelMask);
+#endif
             reply->writeInt32((int32_t) input);
             reply->writeInt32(devices);
             reply->writeInt32(samplingRate);
@@ -1010,7 +1087,13 @@ status_t BnAudioFlinger::onTransact(
         } break;
         case CLOSE_INPUT: {
             CHECK_INTERFACE(IAudioFlinger, data, reply);
+#ifdef STE_AUDIO
+            uint32_t input = data.readInt32();
+            audio_input_clients *inputClientId = (audio_input_clients*) data.readIntPtr();
+            reply->writeInt32(closeInput((audio_io_handle_t) data.readInt32(), inputClientId));
+#else
             reply->writeInt32(closeInput((audio_io_handle_t) data.readInt32()));
+#endif
             return NO_ERROR;
         } break;
         case SET_STREAM_OUTPUT: {
@@ -1146,6 +1229,18 @@ status_t BnAudioFlinger::onTransact(
             reply->writeInt32(getPrimaryOutputFrameCount());
             return NO_ERROR;
         } break;
+#ifdef STE_AUDIO
+        case READ_INPUT: {
+            CHECK_INTERFACE(IAudioFlinger, data, reply);
+            audio_io_handle_t input = data.readInt32();
+            audio_input_clients inputClientId = (audio_input_clients) data.readInt32();
+            void* buffer = (void*) data.readIntPtr();
+            uint32_t bytes = data.readInt32();
+            uint32_t *pOverwrittenBytes = (uint32_t*) data.readIntPtr();
+            reply->writeInt32(readInput(input, inputClientId, buffer, bytes, pOverwrittenBytes));
+            return NO_ERROR;
+        } break;
+#endif
         default:
             return BBinder::onTransact(code, data, reply, flags);
     }
diff --git a/frameworks/av/media/libmedia/IAudioPolicyService.cpp b/frameworks/av/media/libmedia/IAudioPolicyService.cpp
index 386c351..54daaf4 100644
--- a/frameworks/av/media/libmedia/IAudioPolicyService.cpp
+++ b/frameworks/av/media/libmedia/IAudioPolicyService.cpp
@@ -178,7 +178,12 @@ public:
                                     uint32_t samplingRate,
                                     audio_format_t format,
                                     audio_channel_mask_t channelMask,
+#ifdef STE_AUDIO
+                                    int audioSession,
+                                    audio_input_clients *inputClientId)
+#else
                                     int audioSession)
+#endif
     {
         Parcel data, reply;
         data.writeInterfaceToken(IAudioPolicyService::getInterfaceDescriptor());
@@ -186,6 +191,9 @@ public:
         data.writeInt32(samplingRate);
         data.writeInt32(static_cast <uint32_t>(format));
         data.writeInt32(channelMask);
+#ifdef STE_AUDIO
+        data.writeIntPtr((intptr_t)inputClientId);
+#endif
         data.writeInt32(audioSession);
         remote()->transact(GET_INPUT, data, &reply);
         return static_cast <audio_io_handle_t> (reply.readInt32());
@@ -487,12 +495,21 @@ status_t BnAudioPolicyService::onTransact(
             uint32_t samplingRate = data.readInt32();
             audio_format_t format = (audio_format_t) data.readInt32();
             audio_channel_mask_t channelMask = data.readInt32();
+#ifdef STE_AUDIO
+            audio_input_clients *inputClientId =
+                    (audio_input_clients*) data.readIntPtr();
+#endif
             int audioSession = data.readInt32();
             audio_io_handle_t input = getInput(inputSource,
                                                samplingRate,
                                                format,
                                                channelMask,
+#ifdef STE_AUDIO
+                                               audioSession,
+                                               inputClientId);
+#else
                                                audioSession);
+#endif
             reply->writeInt32(static_cast <int>(input));
             return NO_ERROR;
         } break;
diff --git a/frameworks/av/media/libstagefright/ACodec.cpp b/frameworks/av/media/libstagefright/ACodec.cpp
index ca21a4d..08100a8 100644
--- a/frameworks/av/media/libstagefright/ACodec.cpp
+++ b/frameworks/av/media/libstagefright/ACodec.cpp
@@ -567,8 +567,12 @@ status_t ACodec::allocateOutputBuffersFromNativeWindow() {
             mNativeWindow.get(),
             def.format.video.nFrameWidth,
             def.format.video.nFrameHeight,
+#ifdef STE_HARDWARE
+            OMXCodec::OmxToHALFormat(def.format.video.eColorFormat));
+#else
             def.format.video.eColorFormat);
 #endif
+#endif
 
     if (err != 0) {
         ALOGE("native_window_set_buffers_geometry failed: %s (%d)",
@@ -1507,6 +1511,20 @@ status_t ACodec::setSupportedOutputFormat() {
     CHECK_EQ(err, (status_t)OK);
     CHECK_EQ((int)format.eCompressionFormat, (int)OMX_VIDEO_CodingUnused);
 
+    CHECK(format.eColorFormat == OMX_COLOR_FormatYUV420Planar
+           || format.eColorFormat == OMX_COLOR_FormatYUV420SemiPlanar
+           || format.eColorFormat == OMX_COLOR_FormatCbYCrY
+           || format.eColorFormat == OMX_TI_COLOR_FormatYUV420PackedSemiPlanar
+           || format.eColorFormat == OMX_QCOM_COLOR_FormatYVU420SemiPlanar
+#ifdef QCOM_HARDWARE
+           || format.eColorFormat == OMX_QCOM_COLOR_FormatYVU420PackedSemiPlanar32m4ka
+           || format.eColorFormat == OMX_QCOM_COLOR_FormatYUV420PackedSemiPlanar64x32Tile2m8ka
+#endif
+#ifdef STE_HARDWARE
+           || format.eColorFormat == OMX_STE_COLOR_FormatYUV420PackedSemiPlanarMB
+#endif
+         );
+
     return mOMX->setParameter(
             mNode, OMX_IndexParamVideoPortFormat,
             &format, sizeof(format));
diff --git a/frameworks/av/media/libstagefright/CameraSource.cpp b/frameworks/av/media/libstagefright/CameraSource.cpp
index ce045d7..8c01ac2 100644
--- a/frameworks/av/media/libstagefright/CameraSource.cpp
+++ b/frameworks/av/media/libstagefright/CameraSource.cpp
@@ -120,10 +120,16 @@ static int32_t getColorFormat(const char* colorFormat) {
     if (!strcmp(colorFormat, "OMX_TI_COLOR_FormatYUV420PackedSemiPlanar")) {
        return OMX_TI_COLOR_FormatYUV420PackedSemiPlanar;
     }
-
+/*
     if (!strcmp(colorFormat, CameraParameters::PIXEL_FORMAT_ANDROID_OPAQUE)) {
         return OMX_COLOR_FormatAndroidOpaque;
     }
+*/
+#ifdef STE_HARDWARE
+    if (!strcmp(colorFormat, CameraParameters::PIXEL_FORMAT_YUV420MB)) {
+       return OMX_STE_COLOR_FormatYUV420PackedSemiPlanarMB;
+    }
+#endif
 
     ALOGE("Uknown color format (%s), please add it to "
          "CameraSource::getColorFormat", colorFormat);
@@ -569,13 +575,22 @@ status_t CameraSource::initWithCameraAccess(
 
     // XXX: query camera for the stride and slice height
     // when the capability becomes available.
+#ifdef STE_HARDWARE
+    int stride = newCameraParams.getInt(CameraParameters::KEY_RECORD_STRIDE);
+    int sliceHeight = newCameraParams.getInt(CameraParameters::KEY_RECORD_SLICE_HEIGHT);
+#endif
     mMeta = new MetaData;
     mMeta->setCString(kKeyMIMEType,  MEDIA_MIMETYPE_VIDEO_RAW);
     mMeta->setInt32(kKeyColorFormat, mColorFormat);
     mMeta->setInt32(kKeyWidth,       mVideoSize.width);
     mMeta->setInt32(kKeyHeight,      mVideoSize.height);
+#ifdef STE_HARDWARE
+    mMeta->setInt32(kKeyStride,      stride != -1 ? stride : mVideoSize.width);
+    mMeta->setInt32(kKeySliceHeight, sliceHeight != -1 ? sliceHeight : mVideoSize.height);
+#else
     mMeta->setInt32(kKeyStride,      mVideoSize.width);
     mMeta->setInt32(kKeySliceHeight, mVideoSize.height);
+#endif
     mMeta->setInt32(kKeyFrameRate,   mVideoFrameRate);
 
     QCUtils::HFR::setHFRIfEnabled(params, mMeta);
diff --git a/frameworks/av/media/libstagefright/MediaDefs.cpp b/frameworks/av/media/libstagefright/MediaDefs.cpp
index 5d8029c..4b444af 100644
--- a/frameworks/av/media/libstagefright/MediaDefs.cpp
+++ b/frameworks/av/media/libstagefright/MediaDefs.cpp
@@ -24,8 +24,14 @@ const char *MEDIA_MIMETYPE_VIDEO_VPX = "video/x-vnd.on2.vp8";
 const char *MEDIA_MIMETYPE_VIDEO_AVC = "video/avc";
 const char *MEDIA_MIMETYPE_VIDEO_MPEG4 = "video/mp4v-es";
 const char *MEDIA_MIMETYPE_VIDEO_H263 = "video/3gpp";
+#ifdef STE_HARDWARE
+const char *MEDIA_MIMETYPE_VIDEO_H263_SW = "video/3gpp-sw";
+#endif
 const char *MEDIA_MIMETYPE_VIDEO_MPEG2 = "video/mpeg2";
 const char *MEDIA_MIMETYPE_VIDEO_RAW = "video/raw";
+#ifdef STE_HARDWARE
+const char *MEDIA_MIMETYPE_VIDEO_VC1 = "video/vc1";
+#endif
 
 const char *MEDIA_MIMETYPE_AUDIO_AMR_NB = "audio/3gpp";
 const char *MEDIA_MIMETYPE_AUDIO_AMR_WB = "audio/amr-wb";
diff --git a/frameworks/av/media/libstagefright/OMXCodec.cpp b/frameworks/av/media/libstagefright/OMXCodec.cpp
index 2aedd0f..e9f741c 100644
--- a/frameworks/av/media/libstagefright/OMXCodec.cpp
+++ b/frameworks/av/media/libstagefright/OMXCodec.cpp
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-//#define LOG_NDEBUG 0
+//#define LOG_NDEBUG 0
 #define LOG_TAG "OMXCodec"
 #include <utils/Log.h>
 
@@ -308,6 +308,20 @@ void OMXCodec::findMatchingCodecs(
     }
 }
 
+#ifdef STE_HARDWARE
+uint32_t OMXCodec::OmxToHALFormat(OMX_COLOR_FORMATTYPE omxValue) {
+    switch (omxValue) {
+        case OMX_STE_COLOR_FormatYUV420PackedSemiPlanarMB:
+            return HAL_PIXEL_FORMAT_YCBCR42XMBN;
+        case OMX_COLOR_FormatYUV420Planar:
+            return HAL_PIXEL_FORMAT_YCbCr_420_P;
+        default:
+            ALOGI("Unknown OMX pixel format (0x%X), passing it on unchanged", omxValue);
+            return omxValue;
+    }
+}
+#endif
+
 // static
 uint32_t OMXCodec::getComponentQuirks(
         const MediaCodecList *list, size_t index) {
@@ -359,6 +373,12 @@ uint32_t OMXCodec::getComponentQuirks(
                 index, "requires-loaded-to-idle-after-allocation")) {
         quirks |= kRequiresLoadedToIdleAfterAllocation;
     }
+#ifdef STE_HARDWARE
+    if (list->codecHasQuirk(
+                index, "requires-store-metadata-before-idle")) {
+      quirks |= kRequiresStoreMetaDataBeforeIdle;
+    }
+#endif
 #ifdef QCOM_HARDWARE
     if (list->codecHasQuirk(
                 index, "requires-global-flush")) {
@@ -934,6 +954,9 @@ static size_t getFrameSize(
         case OMX_COLOR_FormatYUV420Planar:
         case OMX_COLOR_FormatYUV420SemiPlanar:
         case OMX_TI_COLOR_FormatYUV420PackedSemiPlanar:
+#ifdef STE_HARDWARE
+        case OMX_STE_COLOR_FormatYUV420PackedSemiPlanarMB:
+#endif
         /*
         * FIXME: For the Opaque color format, the frame size does not
         * need to be (w*h*3)/2. It just needs to
@@ -1508,7 +1531,7 @@ status_t OMXCodec::setVideoOutputFormat(
         CHECK_EQ(err, (status_t)OK);
         CHECK_EQ((int)format.eCompressionFormat, (int)OMX_VIDEO_CodingUnused);
 
-#if 0
+//#if 0
         CHECK(format.eColorFormat == OMX_COLOR_FormatYUV420Planar
                || format.eColorFormat == OMX_COLOR_FormatYUV420SemiPlanar
                || format.eColorFormat == OMX_COLOR_FormatCbYCrY
@@ -1519,6 +1542,9 @@ status_t OMXCodec::setVideoOutputFormat(
                || format.eColorFormat == OMX_SEC_COLOR_FormatNV12TPhysicalAddress
                || format.eColorFormat == OMX_SEC_COLOR_FormatNV12Tiled
 #endif
+#ifdef STE_HARDWARE
+               || format.eColorFormat == OMX_STE_COLOR_FormatYUV420PackedSemiPlanarMB
+#endif
                );
 
 #ifdef USE_SAMSUNG_COLORFORMAT
@@ -1530,7 +1556,7 @@ status_t OMXCodec::setVideoOutputFormat(
         }
 #endif
 
-#endif
+//#endif
 
         int32_t colorFormat;
         if (meta->findInt32(kKeyColorFormat, &colorFormat)
@@ -1717,6 +1743,10 @@ void OMXCodec::setComponentRole(
             "video_decoder.mpeg4", "video_encoder.mpeg4" },
         { MEDIA_MIMETYPE_VIDEO_H263,
             "video_decoder.h263", "video_encoder.h263" },
+#ifdef STE_HARDWARE
+        { MEDIA_MIMETYPE_VIDEO_VC1,
+            "video_decoder.vc1", "video_encoder.vc1" },
+#endif
         { MEDIA_MIMETYPE_VIDEO_VPX,
             "video_decoder.vpx", "video_encoder.vpx" },
         { MEDIA_MIMETYPE_AUDIO_RAW,
@@ -1809,6 +1839,16 @@ status_t OMXCodec::init() {
     CHECK_EQ((int)mState, (int)LOADED);
 
     status_t err;
+#ifdef STE_HARDWARE
+    if ((mQuirks & kRequiresStoreMetaDataBeforeIdle)
+        && (mFlags & kStoreMetaDataInVideoBuffers)) {
+        err = mOMX->storeMetaDataInBuffers(mNode, kPortIndexInput, OMX_TRUE);
+        if (err != OK) {
+            ALOGE("Storing meta data in video buffers is not supported");
+            return err;
+        }
+    }
+#endif
     if (!(mQuirks & kRequiresLoadedToIdleAfterAllocation)) {
         err = mOMX->sendCommand(mNode, OMX_CommandStateSet, OMX_StateIdle);
         CHECK_EQ(err, (status_t)OK);
@@ -1875,7 +1915,12 @@ status_t OMXCodec::allocateBuffersOnPort(OMX_U32 portIndex) {
     }
 
     status_t err = OK;
+#ifdef STE_HARDWARE
+    if (!(mQuirks & kRequiresStoreMetaDataBeforeIdle)
+            && (mFlags & kStoreMetaDataInVideoBuffers)
+#else
     if ((mFlags & kStoreMetaDataInVideoBuffers)
+#endif
             && portIndex == kPortIndexInput) {
         err = mOMX->storeMetaDataInBuffers(mNode, kPortIndexInput, OMX_TRUE);
         if (err != OK) {
@@ -2075,7 +2120,11 @@ status_t OMXCodec::allocateOutputBuffersFromNativeWindow() {
             mNativeWindow.get(),
             def.format.video.nFrameWidth,
             def.format.video.nFrameHeight,
+#ifdef STE_HARDWARE
+	     OmxToHALFormat(def.format.video.eColorFormat));
+#else
             def.format.video.eColorFormat);
+#endif
 #else
     OMX_COLOR_FORMATTYPE eColorFormat;
 
@@ -4785,6 +4834,9 @@ static const char *videoCompressionFormatString(OMX_VIDEO_CODINGTYPE type) {
         "OMX_VIDEO_CodingRV",
         "OMX_VIDEO_CodingAVC",
         "OMX_VIDEO_CodingMJPEG",
+#ifdef STE_HARDWARE
+        "OMX_VIDEO_CodingVC1",
+#endif
     };
 
     size_t numNames = sizeof(kNames) / sizeof(kNames[0]);
diff --git a/frameworks/av/media/libstagefright/SurfaceMediaSource.cpp b/frameworks/av/media/libstagefright/SurfaceMediaSource.cpp
index 409038a..2c833c1 100644
--- a/frameworks/av/media/libstagefright/SurfaceMediaSource.cpp
+++ b/frameworks/av/media/libstagefright/SurfaceMediaSource.cpp
@@ -58,7 +58,11 @@ SurfaceMediaSource::SurfaceMediaSource(uint32_t bufferWidth, uint32_t bufferHeig
     mBufferQueue->setDefaultBufferSize(bufferWidth, bufferHeight);
     mBufferQueue->setSynchronousMode(true);
     mBufferQueue->setConsumerUsageBits(GRALLOC_USAGE_HW_VIDEO_ENCODER |
+#ifdef STE_HARDWARE
+            GRALLOC_USAGE_HW_2D);
+#else
             GRALLOC_USAGE_HW_TEXTURE);
+#endif
 
     sp<ISurfaceComposer> composer(ComposerService::getComposerService());
 
diff --git a/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp b/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp
index 597167f..1c8e789 100644
--- a/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp
+++ b/frameworks/av/media/libstagefright/colorconversion/ColorConverter.cpp
@@ -47,6 +47,9 @@ bool ColorConverter::isValid() const {
         case OMX_QCOM_COLOR_FormatYVU420SemiPlanar:
         case OMX_COLOR_FormatYUV420SemiPlanar:
         case OMX_TI_COLOR_FormatYUV420PackedSemiPlanar:
+#ifdef STE_HARDWARE
+        case OMX_STE_COLOR_FormatYUV420PackedSemiPlanarMB:
+#endif
             return true;
 
         default:
@@ -122,6 +125,12 @@ status_t ColorConverter::convert(
             err = convertTIYUV420PackedSemiPlanar(src, dst);
             break;
 
+#ifdef STE_HARDWARE
+        case OMX_STE_COLOR_FormatYUV420PackedSemiPlanarMB:
+            err = convertSTEYUV420PackedSemiPlanarMB(src, dst);
+            break;
+#endif
+
         default:
         {
             CHECK(!"Should not be here. Unknown color conversion.");
@@ -506,6 +515,145 @@ status_t ColorConverter::convertTIYUV420PackedSemiPlanar(
     return OK;
 }
 
+#ifdef STE_HARDWARE
+status_t ColorConverter::convertSTEYUV420PackedSemiPlanarMB(
+        const BitmapParams &src, const BitmapParams &dst) {
+
+    if (!((dst.mWidth & 1) == 0
+            && src.mCropLeft == 0
+            && src.mCropTop == 0
+            && src.cropWidth() == dst.cropWidth()
+            && src.cropHeight() == dst.cropHeight())) {
+        return ERROR_UNSUPPORTED;
+    }
+
+    OMX_U32 mx = src.mWidth / 16;
+    OMX_U32 my = src.mHeight / 16;
+    OMX_U32 lx, ly;
+    OMX_U32 *pChroma, *pLuma = (OMX_U32 *)src.mBits;
+
+    pChroma = (OMX_U32 *)src.mBits + mx * my * 64;
+    for (ly = 0; ly < my; ly++) {
+        for (lx = 0; lx < mx; lx++) {
+            OMX_U32 col, row, lumaWord, chromaWord1 = 0, rgbWord, i;
+            OMX_U8 y[4], cb[4], cr[4], r[4], g[4], b[4];
+            OMX_U32 *dstBuf, *locBuf;
+            OMX_U32 *pBurstLuma = 0, *pBurstChroma = 0;
+            OMX_U32 *pWordLuma = 0, *pWordChroma = 0;
+            OMX_U8 nbOfBlock;
+
+            dstBuf = ((OMX_U32 *)dst.mBits) + (ly * 16) * dst.mWidth / 2;
+            dstBuf += (lx * 16) / 2;
+
+            pBurstLuma = pLuma;
+            pBurstChroma = pChroma;
+
+            for (col = 0; col < 2; col++) {
+                // conversion of a macroblock
+                for (nbOfBlock = 0; nbOfBlock < 2; nbOfBlock++) {
+                    locBuf = dstBuf + 4 * col + 2 * nbOfBlock;
+                    OMX_U32 dstRowOrigo = ly * 16 * dst.mWidth;
+
+                    switch (nbOfBlock) {
+                    case 0:
+                        pWordLuma = pBurstLuma;
+                        pWordChroma = pBurstChroma;
+                        break;
+                    case 1:
+                        pWordLuma = pBurstLuma + 1;
+                        pWordChroma = pBurstChroma + 1;
+                        break;
+                    }
+                    for (row = 0; row < 16; row++) {
+
+                        // Check for cropping on the y axis
+                        if (ly * 16 + row >= dst.mHeight) {
+                            break;
+                        }
+
+                        lumaWord = *pWordLuma;
+                        pWordLuma += 2;
+                        if (row % 2 == 0) {
+                            chromaWord1 = *pWordChroma;
+                            pWordChroma += 2;
+                        }
+
+                        y[3] = ((lumaWord >> 24) & 0xff);
+                        y[2] = ((lumaWord >> 16) & 0xff);
+                        y[1] = ((lumaWord >>  8) & 0xff);
+                        y[0] = ((lumaWord >>  0) & 0xff);
+
+                        cb[0] = cb[1] = ((chromaWord1 >>  0) & 0xff);
+                        cb[2] = cb[3] = ((chromaWord1 >> 16) & 0xff);
+                        cr[0] = cr[1] = ((chromaWord1 >>  8) & 0xff);
+                        cr[2] = cr[3] = ((chromaWord1 >> 24) & 0xff);
+
+                        for (i = 0; i < 4; i++) {
+
+                            int32_t rW,gW,bW;
+
+                            rW = 298 * y[i] + 408 * cr[i] - 57059;
+                            gW = 298 * y[i] - 100 * cb[i] - 208 * cr[i] + 34713;
+                            bW = 298 * y[i] + 516 * cb[i] - 70887;
+
+                            if (rW < 0) {
+                                r[i] = 0;
+                            } else if (rW >= 65536) {
+                                r[i] = 255;
+                            } else {
+                                r[i] = (rW >> 8);
+                            }
+                            if (gW < 0) {
+                                g[i] = 0;
+                            } else if (gW >= 65536) {
+                                g[i] = 255;
+                            } else {
+                                g[i] = (gW >> 8);
+                            }
+                            if (bW < 0) {
+                                b[i] = 0;
+                            } else if (bW >= 65536) {
+                                b[i] = 255;
+                            } else {
+                                b[i] = (bW >> 8);
+                            }
+                            r[i] >>= 3;
+                            g[i] >>= 2;
+                            b[i] >>= 3;
+                        }
+                        for (i = 0; i < 4; i += 2) {
+
+                            // Check for cropping on the x axis
+                            OMX_U32 rowPos = (locBuf - (OMX_U32 *)dst.mBits) * 2 - dstRowOrigo;
+                            if (rowPos >= dst.mWidth) {
+                                locBuf++;
+                                continue;
+                            }
+
+                            rgbWord = (r[i + 1] << 27) +
+                                (g[i + 1] << 21) +
+                                (b[i + 1] << 16) +
+                                (r[i] << 11) +
+                                (g[i] << 5) +
+                                (b[i] << 0);
+                            *locBuf++ = rgbWord;
+                        }
+                        locBuf += dst.mWidth / 2 - 2;
+                        dstRowOrigo += dst.mWidth;
+                    } //end of for 16 loop
+                }  //end of 2 block loop
+                pBurstLuma += 32;
+                pBurstChroma += 16;
+            } // end of 2 col loop
+            pLuma   += 64;
+            pChroma += 32;
+        }
+    }
+
+    return OK;
+}
+#endif
+
 uint8_t *ColorConverter::initClip() {
     static const signed kClipMin = -278;
     static const signed kClipMax = 535;
diff --git a/frameworks/av/media/libstagefright/omx/SoftOMXPlugin.cpp b/frameworks/av/media/libstagefright/omx/SoftOMXPlugin.cpp
index b3fe98e..1806547 100644
--- a/frameworks/av/media/libstagefright/omx/SoftOMXPlugin.cpp
+++ b/frameworks/av/media/libstagefright/omx/SoftOMXPlugin.cpp
@@ -34,6 +34,9 @@ static const struct {
     const char *mRole;
 
 } kComponents[] = {
+#ifdef STE_HARDWARE
+    { "OMX.ST.aac.decoder", "ste_aacdec", "audio_decoder.aac" },
+#endif
     { "OMX.google.aac.decoder", "aacdec", "audio_decoder.aac" },
     { "OMX.google.aac.encoder", "aacenc", "audio_encoder.aac" },
     { "OMX.google.amrnb.decoder", "amrdec", "audio_decoder.amrnb" },
@@ -48,6 +51,9 @@ static const struct {
     { "OMX.google.h263.encoder", "mpeg4enc", "video_encoder.h263" },
     { "OMX.google.mpeg4.decoder", "mpeg4dec", "video_decoder.mpeg4" },
     { "OMX.google.mpeg4.encoder", "mpeg4enc", "video_encoder.mpeg4" },
+#ifdef STE_HARDWARE
+    { "OMX.ST.mp3.decoder", "ste_mp3dec", "audio_decoder.mp3" },
+#endif
     { "OMX.google.mp3.decoder", "mp3dec", "audio_decoder.mp3" },
     { "OMX.google.vorbis.decoder", "vorbisdec", "audio_decoder.vorbis" },
     { "OMX.google.vpx.decoder", "vpxdec", "video_decoder.vpx" },
diff --git a/frameworks/av/services/audioflinger/Android.mk b/frameworks/av/services/audioflinger/Android.mk
index 7fc9872..5a82ea0 100644
--- a/frameworks/av/services/audioflinger/Android.mk
+++ b/frameworks/av/services/audioflinger/Android.mk
@@ -13,6 +13,10 @@ include $(BUILD_STATIC_LIBRARY)
 
 include $(CLEAR_VARS)
 
+ifeq ($(BOARD_USES_STE_HARDWARE),true)
+LOCAL_CFLAGS += -DSTE_AUDIO
+LOCAL_CFLAGS += -Wno-conversion -fpermissive
+endif
 LOCAL_SRC_FILES:=               \
     AudioFlinger.cpp            \
     Threads.cpp                 \
diff --git a/frameworks/av/services/audioflinger/AudioFlinger.cpp b/frameworks/av/services/audioflinger/AudioFlinger.cpp
index 3683f2c..ea39eb3 100644
--- a/frameworks/av/services/audioflinger/AudioFlinger.cpp
+++ b/frameworks/av/services/audioflinger/AudioFlinger.cpp
@@ -1235,6 +1235,20 @@ unsigned int AudioFlinger::getInputFramesLost(audio_io_handle_t ioHandle) const
     return 0;
 }
 
+#ifdef STE_AUDIO
+size_t AudioFlinger::readInput(audio_io_handle_t input, audio_input_clients inputClientId,
+        void *buffer, uint32_t bytes, uint32_t *pOverwrittenBytes)
+{
+    if (input == 0 || buffer == NULL) {
+        return 0;
+    }
+
+    AudioStreamIn* InStream = (AudioStreamIn*)input;
+
+    return 0;
+}
+#endif
+
 status_t AudioFlinger::setVoiceVolume(float value)
 {
     status_t ret = initCheck();
@@ -1863,7 +1877,11 @@ audio_io_handle_t AudioFlinger::openOutput(audio_module_handle_t module,
 #endif
 
         // the first primary output opened designates the primary hw device
+#ifdef STE_AUDIO
+        if ( mPrimaryHardwareDev == NULL ) {
+#else
         if ((mPrimaryHardwareDev == NULL) && (flags & AUDIO_OUTPUT_FLAG_PRIMARY)) {
+#endif
             ALOGI("Using module %d has the primary audio interface", module);
             mPrimaryHardwareDev = outHwDev;
 #ifdef SRS_PROCESSING
@@ -2003,11 +2021,50 @@ status_t AudioFlinger::restoreOutput(audio_io_handle_t output)
     return NO_ERROR;
 }
 
+#ifdef STE_AUDIO
+uint32_t *AudioFlinger::addInputClient(uint32_t clientId)
+{
+    Mutex::Autolock _l(mLock);
+
+    uint32_t *pNewClient = new uint32_t;
+    if (pNewClient) {
+        *pNewClient = clientId;
+        mInputClients.add(pNewClient);
+    }
+
+    return pNewClient;
+}
+
+status_t AudioFlinger::removeInputClient(uint32_t *pClientId)
+{
+    status_t result = NO_ERROR;
+
+    Mutex::Autolock _l(mLock);
+
+    if (pClientId == NULL) {
+        result = BAD_VALUE;
+    } else if (mInputClients.remove(pClientId) < 0) {
+        result = BAD_VALUE;
+    } else {
+        // the pointer was found in the vector and is non-NULL, so it must point to memory	8071
+        // allocated by addInputClient => free it.
+        delete pClientId;
+    }
+
+    return result;
+}
+#endif
+
 audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
                                           audio_devices_t *pDevices,
                                           uint32_t *pSamplingRate,
                                           audio_format_t *pFormat,
+#ifdef STE_AUDIO
+                                          audio_channel_mask_t *pChannelMask,
+                                          audio_input_clients *pInputClientId)
+#else
                                           audio_channel_mask_t *pChannelMask)
+#endif
 {
     status_t status;
     RecordThread *thread = NULL;
@@ -2021,6 +2078,10 @@ audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
     audio_channel_mask_t reqChannels = config.channel_mask;
     audio_stream_in_t *inStream = NULL;
     AudioHwDevice *inHwDev;
+#ifdef STE_AUDIO
+    bool returnRecordThread = true;
+    audio_input_clients inputClientId;
+#endif
 
     if (pDevices == NULL || *pDevices == 0) {
         return 0;
@@ -2032,6 +2093,12 @@ audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
     if (inHwDev == NULL)
         return 0;
 
+#ifdef STE_AUDIO
+    if (pInputClientId != NULL && *pInputClientId == AUDIO_INPUT_CLIENT_PLAYBACK) {
+        returnRecordThread = false;
+    }
+#endif
+
     audio_hw_device_t *inHwHal = inHwDev->hwDevice();
     audio_io_handle_t id = nextUniqueId();
 
@@ -2046,17 +2113,33 @@ audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
                                         &inStream);
 #endif
     ALOGV("openInput() openInputStream returned input %p, SamplingRate %d, Format %d, Channels %x, "
+#ifdef STE_AUDIO
+            "status %d, pInputClientId %p",
+#else
             "status %d",
+#endif
             inStream,
             config.sample_rate,
             config.format,
             config.channel_mask,
+#ifdef STE_AUDIO
+            status,
+            pInputClientId);
+#else
             status);
+#endif
 
     // If the input could not be opened with the requested parameters and we can handle the
     // conversion internally, try to open again with the proposed parameters. The AudioFlinger can
     // resample the input and do mono to stereo or stereo to mono conversions on 16 bit PCM inputs.
-    if (status == BAD_VALUE &&
+#ifdef STE_AUDIO
+    if (inStream == NULL && status == ALREADY_EXISTS) {
+        ALOGD("Input already exists");
+        return 0;
+    } else if (inStream == NULL && status == BAD_VALUE &&
+#else
+     if (status == BAD_VALUE &&
+#endif
         reqFormat == config.format && config.format == AUDIO_FORMAT_PCM_16_BIT &&
         (config.sample_rate <= 2 * reqSamplingRate) &&
         (getInputChannelCount(config.channel_mask) <= FCC_2) && (getInputChannelCount(reqChannels) <= FCC_2)) {
@@ -2135,7 +2218,12 @@ audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
                                   reqChannels,
                                   id,
                                   primaryOutputDevice_l(),
+#ifdef STE_AUDIO
+                                  *pDevices,
+                                  inputClientId
+#else
                                   *pDevices
+#endif
 #ifdef TEE_SINK
                                   , teeSink
 #endif
@@ -2146,6 +2234,12 @@ audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
         if (pFormat != NULL) *pFormat = config.format;
         if (pChannelMask != NULL) *pChannelMask = reqChannels;
 
+#ifdef STE_AUDIO
+        if (pInputClientId != NULL) {
+            *pInputClientId = inputClientId;
+        }
+#endif
+
         // notify client processes of the new input creation
         thread->audioConfigChanged_l(AudioSystem::INPUT_OPENED);
         return id;
@@ -2154,10 +2248,45 @@ audio_io_handle_t AudioFlinger::openInput(audio_module_handle_t module,
     return 0;
 }
 
+#ifdef STE_AUDIO
+status_t AudioFlinger::closeInput(audio_io_handle_t input, audio_input_clients *inputClientId)
+{
+    // keep strong reference on the record thread so that
+    // it is not destroyed while exit() is executed
+    Mutex::Autolock _l(mLock);
+    AudioStreamIn* stream = (AudioStreamIn*)input;
+    audio_input_clients clientId = (audio_input_clients) *inputClientId;
+    sp <RecordThread> thread;
+    thread = checkRecordThread_l(input);
+    if (thread != NULL) {
+        stream = thread->getInput();
+    }
+    if (inputClientId == NULL) {
+        if (thread == NULL) {
+            return BAD_VALUE;
+        }
+        ALOGV("closeInput() %d", input);
+        void *param2 = 0;
+        audioConfigChanged_l(AudioSystem::INPUT_CLOSED, input, param2);
+        mRecordThreads.removeItem(input);
+    }
+
+    AudioStreamIn *in = (AudioStreamIn *)stream;
+    in->hwDev()->close_input_stream(in->hwDev(), in->stream);
+    delete in;
+
+    if (thread != NULL) {
+        thread->exit();
+    }
+
+    return NO_ERROR;
+}
+#else
 status_t AudioFlinger::closeInput(audio_io_handle_t input)
 {
     return closeInput_nonvirtual(input);
 }
+#endif
 
 status_t AudioFlinger::closeInput_nonvirtual(audio_io_handle_t input)
 {
diff --git a/frameworks/av/services/audioflinger/AudioFlinger.h b/frameworks/av/services/audioflinger/AudioFlinger.h
index 2fe5e75..053fab3 100644
--- a/frameworks/av/services/audioflinger/AudioFlinger.h
+++ b/frameworks/av/services/audioflinger/AudioFlinger.h
@@ -196,13 +196,32 @@ public:
 
     virtual status_t restoreOutput(audio_io_handle_t output);
 
+#ifdef STE_AUDIO
+    virtual uint32_t *addInputClient(uint32_t clientId);
+
+    virtual status_t removeInputClient(uint32_t *pClientId);
+#endif
+
     virtual audio_io_handle_t openInput(audio_module_handle_t module,
                                         audio_devices_t *pDevices,
                                         uint32_t *pSamplingRate,
                                         audio_format_t *pFormat,
+#ifdef STE_AUDIO
+                                        audio_channel_mask_t *pChannelMask,
+			                                        audio_input_clients *pInputClientId = NULL);
+
+    virtual status_t closeInput(audio_io_handle_t input, audio_input_clients *inputClientId = NULL);
+    virtual size_t readInput(audio_io_handle_t input,
+                            audio_input_clients inputClientId,
+                            void *buffer,
+                            uint32_t bytes,
+                            uint32_t *pOverwrittenBytes);
+
+#else
                                         audio_channel_mask_t *pChannelMask);
 
     virtual status_t closeInput(audio_io_handle_t input);
+#endif
 
     virtual status_t setStreamOutput(audio_stream_type_t stream, audio_io_handle_t output);
 
@@ -758,6 +777,9 @@ private:
                 int                                 mLPANumChannels;
                 volatile bool                       mAllChainsLocked;
 #endif
+#ifdef STE_AUDIO
+                SortedVector<uint32_t*> mInputClients;
+#endif
                 float       masterVolume_l() const;
                 bool        masterMute_l() const;
                 audio_module_handle_t loadHwModule_l(const char *name);
diff --git a/frameworks/av/services/audioflinger/AudioPolicyService.cpp b/frameworks/av/services/audioflinger/AudioPolicyService.cpp
index e8e3dfa..d622805 100644
--- a/frameworks/av/services/audioflinger/AudioPolicyService.cpp
+++ b/frameworks/av/services/audioflinger/AudioPolicyService.cpp
@@ -269,7 +269,12 @@ audio_io_handle_t AudioPolicyService::getInput(audio_source_t inputSource,
                                     uint32_t samplingRate,
                                     audio_format_t format,
                                     audio_channel_mask_t channelMask,
+#ifdef STE_AUDIO
+                                    int audioSession,
+                                    audio_input_clients *inputClientId)
+#else
                                     int audioSession)
+#endif
 {
     if (mpAudioPolicy == NULL) {
         return 0;
@@ -281,7 +286,11 @@ audio_io_handle_t AudioPolicyService::getInput(audio_source_t inputSource,
     Mutex::Autolock _l(mLock);
     // the audio_in_acoustics_t parameter is ignored by get_input()
     audio_io_handle_t input = mpAudioPolicy->get_input(mpAudioPolicy, inputSource, samplingRate,
+#ifdef STE_AUDIO
+                                                   format, channelMask, (audio_in_acoustics_t) 0, inputClientId);
+#else
                                                    format, channelMask, (audio_in_acoustics_t) 0);
+#endif
 
     if (input == 0) {
         return input;
@@ -1027,6 +1036,14 @@ void AudioPolicyService::AudioCommandThread::insertCommand_l(AudioCommand *comma
         for (size_t k = i + 1; k < mAudioCommands.size(); k++) {
             if (mAudioCommands[k] == removedCommands[j]) {
                 ALOGV("suppressing command: %d", mAudioCommands[k]->mCommand);
+#ifdef STE_AUDIO
+                // for commands that are not filtered,
+                // command->mParam is deleted in threadLoop
+                ALOGV("deleting mParam %p for command: %d",
+                        mAudioCommands[k]->mParam, mAudioCommands[k]->mCommand);
+                delete mAudioCommands[k]->mParam;
+                mAudioCommands[k]->mParam = NULL;
+#endif
                 mAudioCommands.removeAt(k);
                 break;
             }
@@ -1513,7 +1530,12 @@ static audio_io_handle_t aps_open_input(void *service,
                                         uint32_t *pSamplingRate,
                                         audio_format_t *pFormat,
                                         audio_channel_mask_t *pChannelMask,
+#ifdef STE_AUDIO
+                                        audio_in_acoustics_t acoustics,
+			                    audio_input_clients *inputClientId)
+#else
                                         audio_in_acoustics_t acoustics)
+#endif
 {
     sp<IAudioFlinger> af = AudioSystem::get_audio_flinger();
     if (af == 0) {
@@ -1521,7 +1543,11 @@ static audio_io_handle_t aps_open_input(void *service,
         return 0;
     }
 
+#ifdef STE_AUDIO
+    return af->openInput((audio_module_handle_t)0, pDevices, pSamplingRate, pFormat, pChannelMask, inputClientId);
+#else
     return af->openInput((audio_module_handle_t)0, pDevices, pSamplingRate, pFormat, pChannelMask);
+#endif
 }
 
 static audio_io_handle_t aps_open_input_on_module(void *service,
@@ -1529,7 +1555,12 @@ static audio_io_handle_t aps_open_input_on_module(void *service,
                                                   audio_devices_t *pDevices,
                                                   uint32_t *pSamplingRate,
                                                   audio_format_t *pFormat,
+#ifdef STE_AUDIO
+                                                  audio_channel_mask_t *pChannelMask,
+                                                  audio_input_clients *inputClientId)
+#else
                                                   audio_channel_mask_t *pChannelMask)
+#endif
 {
     sp<IAudioFlinger> af = AudioSystem::get_audio_flinger();
     if (af == 0) {
@@ -1537,16 +1568,29 @@ static audio_io_handle_t aps_open_input_on_module(void *service,
         return 0;
     }
 
+#ifdef STE_AUDIO
+    return af->openInput(module, pDevices, pSamplingRate, pFormat, pChannelMask, inputClientId);
+#else
     return af->openInput(module, pDevices, pSamplingRate, pFormat, pChannelMask);
+#endif
 }
 
+#ifdef STE_AUDIO
+static int aps_close_input(void *service, audio_io_handle_t input,
+                            audio_input_clients *inputClientId = NULL)
+#else
 static int aps_close_input(void *service, audio_io_handle_t input)
+#endif
 {
     sp<IAudioFlinger> af = AudioSystem::get_audio_flinger();
     if (af == 0)
         return PERMISSION_DENIED;
 
+#ifdef STE_AUDIO
+    return af->closeInput(input, inputClientId);
+#else
     return af->closeInput(input);
+#endif
 }
 
 static int aps_set_stream_output(void *service, audio_stream_type_t stream,
diff --git a/frameworks/av/services/audioflinger/AudioPolicyService.h b/frameworks/av/services/audioflinger/AudioPolicyService.h
index 3e01713..6848156 100644
--- a/frameworks/av/services/audioflinger/AudioPolicyService.h
+++ b/frameworks/av/services/audioflinger/AudioPolicyService.h
@@ -78,7 +78,12 @@ public:
                                     uint32_t samplingRate = 0,
                                     audio_format_t format = AUDIO_FORMAT_DEFAULT,
                                     audio_channel_mask_t channelMask = 0,
+#ifdef STE_AUDIO
+                                    int audioSession = 0,
+                                    audio_input_clients *inputClientId = NULL);
+#else
                                     int audioSession = 0);
+#endif
     virtual status_t startInput(audio_io_handle_t input);
     virtual status_t stopInput(audio_io_handle_t input);
     virtual void releaseInput(audio_io_handle_t input);
diff --git a/frameworks/av/services/audioflinger/Effects.h b/frameworks/av/services/audioflinger/Effects.h
index 58f3ddc..cefe37b 100644
--- a/frameworks/av/services/audioflinger/Effects.h
+++ b/frameworks/av/services/audioflinger/Effects.h
@@ -220,6 +220,10 @@ protected:
     EffectHandle(const EffectHandle&);
     EffectHandle& operator =(const EffectHandle&);
 
+#ifdef STE_AUDIO
+    Mutex               mLock;          // mutex protecting mEffect pointer
+#endif
+
     sp<EffectModule> mEffect;           // pointer to controlled EffectModule
     sp<IEffectClient> mEffectClient;    // callback interface for client notifications
     /*const*/ sp<Client> mClient;       // client for shared memory allocation, see disconnect()
diff --git a/frameworks/av/services/audioflinger/Threads.cpp b/frameworks/av/services/audioflinger/Threads.cpp
index bca1549..afa3130 100644
--- a/frameworks/av/services/audioflinger/Threads.cpp
+++ b/frameworks/av/services/audioflinger/Threads.cpp
@@ -1480,6 +1480,9 @@ void AudioFlinger::PlaybackThread::audioConfigChanged_l(int event, int param) {
         break;
 
     case AudioSystem::STREAM_CONFIG_CHANGED:
+#ifdef STE_AUDIO
+    case AudioSystem::SINK_LATENCY_CHANGED:
+#endif
         param2 = &param;
     case AudioSystem::OUTPUT_CLOSED:
     default:
@@ -3102,6 +3105,12 @@ bool AudioFlinger::MixerThread::checkForNewParameters_l()
             }
         }
 
+#ifdef STE_AUDIO
+        if (param.getInt(String8(AudioParameter::keySinkLatency), value) == NO_ERROR) {
+            sendIoConfigEvent_l(AudioSystem::SINK_LATENCY_CHANGED, value);
+        }
+#endif
+
         if (status == NO_ERROR) {
             status = mOutput->stream->common.set_parameters(&mOutput->stream->common,
                                                     keyValuePair.string());
@@ -3685,7 +3694,12 @@ AudioFlinger::RecordThread::RecordThread(const sp<AudioFlinger>& audioFlinger,
                                          audio_channel_mask_t channelMask,
                                          audio_io_handle_t id,
                                          audio_devices_t outDevice,
+#ifdef STE_AUDIO
+                                         audio_devices_t inDevice,
+                                         audio_input_clients pInputClientId
+#else
                                          audio_devices_t inDevice
+#endif
 #ifdef TEE_SINK
                                          , const sp<NBAIO_Sink>& teeSink
 #endif
@@ -3702,7 +3716,9 @@ AudioFlinger::RecordThread::RecordThread(const sp<AudioFlinger>& audioFlinger,
 #endif
 {
     snprintf(mName, kNameLength, "AudioIn_%X", id);
-
+#ifdef STE_AUDIO
+    mInputClientId = pInputClientId;
+#endif
     readInputParameters();
 
 }
@@ -4550,6 +4566,12 @@ KeyedVector<int, bool> AudioFlinger::RecordThread::sessionIds() const
     return ids;
 }
 
+AudioFlinger::AudioStreamIn* AudioFlinger::RecordThread::getInput() const
+{
+    Mutex::Autolock _l(mLock);
+    return mInput;
+}
+
 AudioFlinger::AudioStreamIn* AudioFlinger::RecordThread::clearInput()
 {
     Mutex::Autolock _l(mLock);
diff --git a/frameworks/av/services/audioflinger/Threads.h b/frameworks/av/services/audioflinger/Threads.h
index c9de0a2..de0f8fd 100644
--- a/frameworks/av/services/audioflinger/Threads.h
+++ b/frameworks/av/services/audioflinger/Threads.h
@@ -713,7 +713,12 @@ public:
                     audio_channel_mask_t channelMask,
                     audio_io_handle_t id,
                     audio_devices_t outDevice,
+#ifdef STE_AUDIO
+                    audio_devices_t inDevice,
+                    audio_input_clients pinputClientId
+#else
                     audio_devices_t inDevice
+#endif
 #ifdef TEE_SINK
                     , const sp<NBAIO_Sink>& teeSink
 #endif
@@ -755,6 +760,7 @@ public:
             bool        stop_l(RecordTrack* recordTrack);
 
             void        dump(int fd, const Vector<String16>& args);
+            AudioStreamIn* getInput() const;
             AudioStreamIn* clearInput();
             virtual audio_stream_t* stream() const;
 
@@ -806,6 +812,9 @@ private:
             const uint32_t                      mReqChannelCount;
             const uint32_t                      mReqSampleRate;
             ssize_t                             mBytesRead;
+#ifdef STE_AUDIO
+            audio_input_clients                 mInputClientId;
+#endif
             // sync event triggering actual audio capture. Frames read before this event will
             // be dropped and therefore not read by the application.
             sp<SyncEvent>                       mSyncStartEvent;
diff --git a/frameworks/av/services/camera/libcameraservice/CameraHardwareInterface.h b/frameworks/av/services/camera/libcameraservice/CameraHardwareInterface.h
index 2bdf827..120be8d 100644
--- a/frameworks/av/services/camera/libcameraservice/CameraHardwareInterface.h
+++ b/frameworks/av/services/camera/libcameraservice/CameraHardwareInterface.h
@@ -640,7 +640,7 @@ private:
 
     static int __set_usage(struct preview_stream_ops* w, int usage)
     {
-#ifdef HTC_3D_SUPPORT
+#ifdef HTC_3D_SUPPORT || STE_HARDWARE
         usage |= GRALLOC_USAGE_PRIVATE_0;
 #endif
         ANativeWindow *a = anw(w);
